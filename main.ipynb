{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manika/anaconda3/envs/tf14/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/manika/anaconda3/envs/tf14/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import LinearSVC\n",
    "from scipy.ndimage.measurements import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import time\n",
    "import h5py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the vehicle and non-vehicle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of car images:  8792\n",
      "No. of non-car images:  8968\n"
     ]
    }
   ],
   "source": [
    "car = glob.glob('vehicles/**/*.png')\n",
    "noncar = glob.glob('non-vehicles/**/*.png')\n",
    "print (\"No. of car images: \", len(car))\n",
    "print (\"No. of non-car images: \", len(noncar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = []\n",
    "for image in car:\n",
    "    cars.append(cv2.imread(image))\n",
    "non_cars = []\n",
    "for image in noncar:\n",
    "    non_cars.append(cv2.imread(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8792\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "print (len(cars))\n",
    "print (len(non_cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.asarray(cars[0:7000] + non_cars[0:7000])\n",
    "# y = np.asarray([1]*len(cars[0:7000]) + [0]*len(non_cars[0:7000]))\n",
    "X = np.asarray(cars + non_cars)\n",
    "y = np.asarray([1]*len(cars) + [0]*len(non_cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_norm = (X/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y, numOfClasses):\n",
    "    \"\"\"\n",
    "    Converts label into one-hot encoding.\n",
    "    takes in the labels and the number of classes \n",
    "    \"\"\"\n",
    "    encoded = np.zeros((y.shape[0],numOfClasses))\n",
    "    for i in range(y.shape[0]):\n",
    "        encoded[i][y[i]] = 1.0\n",
    "    return encoded\n",
    "\n",
    "y_encoded = one_hot_encoding(y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14208 samples, validate on 3552 samples\n",
      "Epoch 1/10\n",
      "14208/14208 [==============================] - 61s 4ms/step - loss: 0.0772 - acc: 0.9043 - val_loss: 0.0280 - val_acc: 0.9733\n",
      "Epoch 2/10\n",
      "14208/14208 [==============================] - 59s 4ms/step - loss: 0.0241 - acc: 0.9721 - val_loss: 0.0154 - val_acc: 0.9817\n",
      "Epoch 3/10\n",
      "14208/14208 [==============================] - 62s 4ms/step - loss: 0.0157 - acc: 0.9828 - val_loss: 0.0105 - val_acc: 0.9896\n",
      "Epoch 4/10\n",
      "14208/14208 [==============================] - 59s 4ms/step - loss: 0.0122 - acc: 0.9861 - val_loss: 0.0082 - val_acc: 0.9913\n",
      "Epoch 5/10\n",
      "14208/14208 [==============================] - 64s 4ms/step - loss: 0.0107 - acc: 0.9875 - val_loss: 0.0081 - val_acc: 0.9896\n",
      "Epoch 6/10\n",
      "14208/14208 [==============================] - 64s 4ms/step - loss: 0.0097 - acc: 0.9885 - val_loss: 0.0077 - val_acc: 0.9901\n",
      "Epoch 7/10\n",
      "14208/14208 [==============================] - 76s 5ms/step - loss: 0.0084 - acc: 0.9899 - val_loss: 0.0106 - val_acc: 0.9859\n",
      "Epoch 8/10\n",
      "14208/14208 [==============================] - 64s 5ms/step - loss: 0.0081 - acc: 0.9902 - val_loss: 0.0052 - val_acc: 0.9944\n",
      "Epoch 9/10\n",
      "14208/14208 [==============================] - 63s 4ms/step - loss: 0.0065 - acc: 0.9918 - val_loss: 0.0054 - val_acc: 0.9938\n",
      "Epoch 10/10\n",
      "14208/14208 [==============================] - 62s 4ms/step - loss: 0.0065 - acc: 0.9923 - val_loss: 0.0054 - val_acc: 0.9924\n",
      "Test score: 0.005407127553883231\n",
      "Test accuracy: 0.9923986486486487\n"
     ]
    }
   ],
   "source": [
    "def get_conv(input_shape=(64, 64, 3), filename=None):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1., input_shape=input_shape, output_shape=input_shape))\n",
    "    model.add(Convolution2D(10, 3, 3, activation='relu', name='conv1', input_shape=input_shape, border_mode=\"same\"))\n",
    "    model.add(Convolution2D(10, 3, 3, activation='relu', name='conv2', border_mode=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Convolution2D(128, 8, 8, activation=\"relu\", name=\"dense1\")) # This was Dense(128)\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(1, 1, 1, name=\"dense2\", activation=\"tanh\")) # This was Dense(1)\n",
    "    if filename:\n",
    "        model.load_weights(filename)        \n",
    "    return model\n",
    "\n",
    "model = get_conv()\n",
    "model.add(Flatten())\n",
    "model.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, nb_epoch=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"result_new_.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "model = get_conv(input_shape=(None,None,3), filename=\"result_new_.h5\")\n",
    "\n",
    "prev_hot_windows1 = []\n",
    "prev_hot_windows2 = []\n",
    "prev_hot_windows3 = []\n",
    "\n",
    "\n",
    "def process2(img):   \n",
    "    global prev_hot_windows1, prev_hot_windows2, prev_hot_windows3    \n",
    "    pred = model.predict(img.reshape(1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(pred.shape[2]),np.arange(pred.shape[1]))\n",
    "    box_x = (xx[pred[0, :, :, 0] > 0.99])\n",
    "    box_y = (yy[pred[0, :, :, 0] > 0.99])\n",
    "    \n",
    "    heat = np.zeros_like(img[:, :, 0]).astype(np.float)\n",
    "\n",
    "    for x, y in zip(box_x, box_y):\n",
    "        if (y*8 > 375) & (x*8 > 500):\n",
    "            x1 = x*8\n",
    "            x2 = x*8 + 70\n",
    "            y1 = y*8\n",
    "            y2 = y*8 + 70\n",
    "            heat[y1:y2, x1:x2] += 1\n",
    "            \n",
    "    for bbox in prev_hot_windows1:\n",
    "        heat[(bbox[0][1]):(bbox[1][1]), (bbox[0][0]):(bbox[1][0])] += 4\n",
    "    for bbox in prev_hot_windows2:\n",
    "        heat[(bbox[0][1]):(bbox[1][1]), (bbox[0][0]):(bbox[1][0])] += 3   \n",
    "    for bbox in prev_hot_windows3:\n",
    "        heat[(bbox[0][1]):(bbox[1][1]), (bbox[0][0]):(bbox[1][0])] += 2          \n",
    "            \n",
    "    heat[heat <= 9] = 0\n",
    "    \n",
    "    prev_hot_windows3 = list(prev_hot_windows2)\n",
    "    prev_hot_windows2 = list(prev_hot_windows1)\n",
    "    prev_hot_windows1 = []\n",
    "    \n",
    "    labels = label(heat)\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        w = np.max(nonzerox)-np.min(nonzerox)\n",
    "        h = np.max(nonzeroy)-np.min(nonzeroy)\n",
    "        if (50 < w < 400) & (25 < h < 250):\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0, 0, 255), 6) \n",
    "            prev_hot_windows1.append(bbox)\n",
    "            \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video result_video_.mp4\n",
      "[MoviePy] Writing video result_video_.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [15:26<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: result_video_.mp4 \n",
      "\n",
      "CPU times: user 28min 54s, sys: 4min 34s, total: 33min 28s\n",
      "Wall time: 15min 29s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "result_file2 = 'result_video_.mp4'\n",
    "clip2 = VideoFileClip('test_video.mp4')\n",
    "clip2_ = clip2.fl_image(process2) \n",
    "%time clip2_.write_videofile(result_file2, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
